{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d869eae7",
   "metadata": {},
   "source": [
    "## What is Textblob\n",
    "\n",
    "* Textblob is an open-source python library used to perform NLP activities like Lemmatization, Stemming, Tokenization, Noun Phrase Extraction, POS Tagging, N-Grams, Sentiment Analysis. \n",
    "\n",
    "* It is faster than NLTK, however it does not provide the functionalities like vectorization, dependency parsing.\n",
    "\n",
    "* Text Classification, Sentiment Analysis can be performed using Textblob. \n",
    "* Official Link to Textblob is: https://textblob.readthedocs.io/en/dev/\n",
    "\n",
    "* Installation: pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0c543",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Install Textblob\n",
    "!pip install nltk\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5213c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a807ca3",
   "metadata": {},
   "source": [
    "### Functionalities of Textblob\n",
    "* Language Detection\n",
    "* Word Correction\n",
    "* Word Count\n",
    "* Phrase Extraction\n",
    "* POS Tagging\n",
    "* Tokenization\n",
    "* Plularization of words using Textblob\n",
    "* Lemmatization using Textblob\n",
    "* n-gram in Textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059517a",
   "metadata": {},
   "source": [
    "#### Language Detection\n",
    "* With the help of Google Translate, Textblob detects the language of input text. \n",
    "* Textblob is also able to translate text from one language to another language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fdb42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SK074909\\Anaconda3\\envs\\Rython\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\SK074909\\Anaconda3\\envs\\Rython\\lib\\site-packages\\numpy\\.libs\\libopenblas.noijjg62emaszi6nyurl6jbkm4evbgm7.gfortran-win_amd64.dll\n",
      "C:\\Users\\SK074909\\Anaconda3\\envs\\Rython\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\SK074909\\Anaconda3\\envs\\Rython\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Language is: en\n",
      "Input text in Spanish: hola juan como estas\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    " \n",
    "blob = TextBlob(\"Hey John, How are You\")\n",
    " \n",
    "print(\"Detected Language is:\",blob.detect_language())\n",
    " \n",
    "print(\"Input text in Spanish:\",blob.translate(to='es'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710e0b7",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Since Google has made some changes into its API and Textblob is using the older API, as a result you may get 404 error. To avoide this, change the url given in translate.py under your environment. \n",
    "\n",
    "\n",
    "updated url link is:\n",
    "url = \"http://translate.google.com/translate_a/t?client=te&format=html&dt=bd&dt=ex&dt=ld&dt=md&dt=qca&dt=rw&dt=rm&dt=ss&dt=t&dt=at&ie=UTF-8&oe=UTF-8&otf=2&ssel=0&tsel=0&kc=1\"\n",
    "\n",
    "\n",
    "Location of translate.py file: C:\\Users\\<user name>\\Anaconda3\\envs\\Rython\\Lib\\site-packages\\textblob\\translate.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe5f92",
   "metadata": {},
   "source": [
    "#### Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf80d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "text=\"\"\" ABCD Corp alays values ttheir employees!!!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0757e15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ABCD Corp alays values ttheir employees!!!\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe50b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddbd582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\" ABCD Corp alays values ttheir employees!!!\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0941e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\" ABCD For always values their employees!!!\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29eab446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"has\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob('hasss').correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "049a9342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"or\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sometimes it failsas well\n",
    "TextBlob('ur').correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3704f",
   "metadata": {},
   "source": [
    "### Word Count \n",
    "With the help of word count, we can count the frequency of words or a noun phrase in a given sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1169c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Sentiment Analysis is a process by which we can find the sentiment of a text. Sentiment can be Positive, Negative or Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad31d646",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b830875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts[\"analysis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9daa2972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fbf1a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a39c4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts[\"Analysis\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3582855",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "With the help of tags function of textblob, we can get tag each words of a sentence with a tag that can be either noun, pronoun, verb, adverb, adjective and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "680e50c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Adam', 'NNP'), ('I', 'PRP'), ('like', 'VBP'), ('to', 'TO'), ('read', 'VB'), ('about', 'IN'), ('NLP', 'NNP'), ('I', 'PRP'), ('work', 'VBP'), ('at', 'IN'), ('ABCD', 'NNP'), ('Corp', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    " \n",
    "text = TextBlob(\"My name is Adam. I like to read about NLP. I work at ABCD Corp.\")\n",
    "print(text.tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18a7c0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('My', 'PRP$')\n",
      "('name', 'NN')\n",
      "('is', 'VBZ')\n",
      "('Adam', 'NNP')\n",
      "('I', 'PRP')\n",
      "('like', 'VBP')\n",
      "('to', 'TO')\n",
      "('read', 'VB')\n",
      "('about', 'IN')\n",
      "('NLP', 'NNP')\n",
      "('I', 'PRP')\n",
      "('work', 'VBP')\n",
      "('at', 'IN')\n",
      "('ABCD', 'NNP')\n",
      "('Corp', 'NNP')\n"
     ]
    }
   ],
   "source": [
    "new_tuple=[]\n",
    "for i in text.tags:\n",
    "    print(i)\n",
    "    if 'VBP' not in i[1]:\n",
    "        new_tuple.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2a4260c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('My', 'PRP$'),\n",
       " ('name', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('Adam', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('read', 'VB'),\n",
       " ('about', 'IN'),\n",
       " ('NLP', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " ('at', 'IN'),\n",
       " ('ABCD', 'NNP'),\n",
       " ('Corp', 'NNP')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2be7d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "value=''\n",
    "for i in new_tuple:\n",
    "    value=value+\" \" + \"\".join(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d3a2219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' My name is Adam I to read about NLP I at ABCD Corp'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570dce4",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee75c7a",
   "metadata": {},
   "source": [
    "* Corpus (or corpora in plural) - Corpus is nothing but a collection of text data. The text maybe in one language or maybe a combination of two or more. \n",
    "\n",
    "* Token - The term \"Token\" is nothing but the total number of words in a text, corpus etc, regardless of their freuqncy of occurrence in the text. Tokens are nothing but a string of contiguous characters which either lies between the two spaces or it lies between a space and punctuation. For Example: Suppose you have the following string : \"abc_123_defg\", if you split it on basis of underscores \"_\" you obtained three tokens : \"abc\", \"123\" and \"defg\".\n",
    "\n",
    "**What is tokenization?**\n",
    "\n",
    "Tokenization is a process of splitting the sentence or corpus into its smalles unit i.e. \"Tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a0bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"\n",
    "R is a comprehensive statistical and graphical programming language, which is fast gaining popularity among data analysts. It is free and runs on a variety of platforms, including Windows, Unix, and macOS. It provides an unparalleled platform for programming new statistical methods in an easy and straightforward manner. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d13f6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_object = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b60b83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word tokenization of the sample corpus\n",
    "corpus_words = blob_object.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a87be64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['R', 'is', 'a', 'comprehensive', 'statistical', 'and', 'graphical', 'programming', 'language', 'which', 'is', 'fast', 'gaining', 'popularity', 'among', 'data', 'analysts', 'It', 'is', 'free', 'and', 'runs', 'on', 'a', 'variety', 'of', 'platforms', 'including', 'Windows', 'Unix', 'and', 'macOS', 'It', 'provides', 'an', 'unparalleled', 'platform', 'for', 'programming', 'new', 'statistical', 'methods', 'in', 'an', 'easy', 'and', 'straightforward', 'manner'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45a3f96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fd6bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_sentences= blob_object.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5528532a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"\n",
       " R is a comprehensive statistical and graphical programming language, which is fast gaining popularity among data analysts.\"),\n",
       " Sentence(\"It is free and runs on a variety of platforms, including Windows, Unix, and macOS.\"),\n",
       " Sentence(\"It provides an unparalleled platform for programming new statistical methods in an easy and straightforward manner.\")]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b598ee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(corpus_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f396561",
   "metadata": {},
   "source": [
    "#### Pluralization of words using Textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "547f7446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Platforms'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "w = Word('Platform')\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdf342db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Platformss'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "w = Word('Platforms')\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6343f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platforms\n",
      "sciences\n",
      "communities\n",
      "etcs\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Great Learning is a great platform to learn data science. \\n It helps community through blogs, Youtube, GLA,etc.\")\n",
    "for word,pos in blob.tags:\n",
    "    if pos == 'NN':\n",
    "        print (word.pluralize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3cb03",
   "metadata": {},
   "source": [
    "#### Lemmatization using Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9d5ddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL: Great | LEMMA: Great | STEM: great\n",
      "ORIGINAL: Learning | LEMMA: Learning | STEM: learn\n",
      "ORIGINAL: is | LEMMA: is | STEM: is\n",
      "ORIGINAL: a | LEMMA: a | STEM: a\n",
      "ORIGINAL: great | LEMMA: great | STEM: great\n",
      "ORIGINAL: platform | LEMMA: platform | STEM: platform\n",
      "ORIGINAL: to | LEMMA: to | STEM: to\n",
      "ORIGINAL: learn | LEMMA: learn | STEM: learn\n",
      "ORIGINAL: data | LEMMA: data | STEM: data\n",
      "ORIGINAL: science | LEMMA: science | STEM: scienc\n",
      "ORIGINAL: It | LEMMA: It | STEM: it\n",
      "ORIGINAL: helps | LEMMA: help | STEM: help\n",
      "ORIGINAL: community | LEMMA: community | STEM: commun\n",
      "ORIGINAL: through | LEMMA: through | STEM: through\n",
      "ORIGINAL: blogs | LEMMA: blog | STEM: blog\n",
      "ORIGINAL: Youtube | LEMMA: Youtube | STEM: youtub\n",
      "ORIGINAL: GLA | LEMMA: GLA | STEM: gla\n",
      "ORIGINAL: etc | LEMMA: etc | STEM: etc\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Great Learning is a great platform to learn data science. \\n It helps community through blogs, Youtube, GLA,etc.\")\n",
    "words = blob.words\n",
    "\n",
    "for word in words:\n",
    "    print(\"ORIGINAL:\", word, \"| LEMMA:\", word.lemmatize(), \"| STEM:\", word.stem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word('learning')\n",
    "w.lemmatize(\"n\") ## v here represents verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word('learning')\n",
    "w.lemmatize(\"v\") ## v here represents verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word('peoples')\n",
    "w.lemmatize(\"n\") ## v here represents verb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01024e7c",
   "metadata": {},
   "source": [
    "#### n-gram in Textblob\n",
    "\n",
    "An N-gram is an N-token sequence of words: a 2-gram (more commonly called a bigram) is a two-word sequence of words like “really good”, “not good”, or “your homework”, and a 3-gram (more commonly called a trigram) is a three-word sequence of words like “not at all”, or “turn off light”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.ngrams(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a47ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.ngrams(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3346e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ce261",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.ngrams(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679995b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
